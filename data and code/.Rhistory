print(cor(beta, estimated_beta))
library(numDeriv)
# The number of test takers and number of items
N <- 50
J <- 5
# Ground truth for person and item parameters
set.seed(11111)  # for reproducibility
tau <- round(rnorm(N, 0, 0.25), 3)
tau <- tau - mean(tau)  # Enforce identifiability constraint
beta <- round(rnorm(J, 1.8, 0.25), 3)
alpha <- round(runif(J, 1.75, 3.25), 3)
# Data generation function
generate_data <- function(N, J, true_tau, true_beta, true_alpha, c){
time_matrix <- matrix(nrow = N, ncol = J)
for(j in 1:J){
for(i in 1:N){
time_matrix[i,j] <- rnorm(1, mean = true_beta[j] - true_tau[i], sd = 1/true_alpha[j])
}
}
censored_data <- pmin(time_matrix, c)
censor_rate <- sum(time_matrix > c) / (N*J)
return(list(time_matrix = time_matrix, censored_data = censored_data, censor_rate = censor_rate))
}
raw_data <- generate_data(N, J, tau, beta, alpha, 2.5)
# Log-likelihood function
log_likelihood_function <- function(params, dat, N, J, c){
tau <- params[1:N]
alpha <- params[(N+1):(N+J)]
beta <- params[(N+J+1):(N+2*J)]
ll <- 0
for(i in 1:N) {
for(j in 1:J) {
if(dat[i,j] < c) {
ll <- ll + dnorm(dat[i,j], mean = beta[j] - tau[i], sd = 1/alpha[j], log = TRUE)
} else {
ll <- ll + dnorm(dat[i,j], mean = beta[j] - tau[i], sd = 1/alpha[j])
+ pnorm(c, mean = beta[j] - tau[i], sd = 1/alpha[j], lower.tail = FALSE, log.p = TRUE)
}
}
}
return(-ll)
}
# Initial parameter values
init_params <- c(rep(0, N), rep(1, J), rep(0, J))
# Optimization
optim_result <- optim(init_params, log_likelihood_function,
dat = raw_data$censored_data, N = N, J = J, c = 2.5,
method = "L-BFGS-B")
# Extract estimated parameters
estimated_tau <- optim_result$par[1:N]
estimated_alpha <- optim_result$par[(N+1):(N+J)]
estimated_beta <- optim_result$par[(N+J+1):(N+2*J)]
# Enforce identifiability constraint on estimated tau
estimated_tau <- estimated_tau - mean(estimated_tau)
# Compare true and estimated parameters
print(cor(tau, estimated_tau))
print(cor(alpha, estimated_alpha))
print(cor(beta, estimated_beta))
max_iter <- 100
for(iter in 1:max_iter){
}
library(numDeriv)
# The number of test takers and number of items
N <- 50
J <- 5
# Ground truth for person and item parameters
set.seed(11111)  # for reproducibility
tau <- round(rnorm(N, 0, 0.25), 3)
tau <- tau - mean(tau)  # Enforce identifiability constraint
beta <- round(rnorm(J, 1.8, 0.25), 3)
alpha <- round(runif(J, 1.75, 3.25), 3)
# Data generation function
generate_data <- function(N, J, true_tau, true_beta, true_alpha, c){
time_matrix <- matrix(nrow = N, ncol = J)
for(j in 1:J){
for(i in 1:N){
time_matrix[i,j] <- rnorm(1, mean = true_beta[j] - true_tau[i], sd = 1/true_alpha[j])
}
}
censored_data <- pmin(time_matrix, c)
censor_rate <- sum(time_matrix > c) / (N*J)
return(list(time_matrix = time_matrix, censored_data = censored_data, censor_rate = censor_rate))
}
raw_data <- generate_data(N, J, tau, beta, alpha, 2.5)
# Log-likelihood function
log_likelihood_function <- function(params, dat, N, J, c){
tau <- params[1:N]
alpha <- params[(N+1):(N+J)]
beta <- params[(N+J+1):(N+2*J)]
ll <- 0
for(i in 1:N) {
for(j in 1:J) {
if(dat[i,j] < c) {
ll <- ll + dnorm(dat[i,j], mean = beta[j] - tau[i], sd = 1/alpha[j], log = TRUE)
} else {
ll <- ll + dnorm(dat[i,j], mean = beta[j] - tau[i], sd = 1/alpha[j])
+ pnorm(c, mean = beta[j] - tau[i], sd = 1/alpha[j], lower.tail = FALSE, log.p = TRUE)
}
}
}
return(-ll)
}
# Initial parameter values
init_params <- c(rep(0, N), rep(0, J), rep(0, J))
max_iter <- 100
for(iter in 1:max_iter){
}
# Optimization
optim_result <- optim(init_params, log_likelihood_function,
dat = raw_data$censored_data, N = N, J = J, c = 2.5,
method = "L-BFGS-B")
library(numDeriv)
# The number of test takers and number of items
N <- 50
J <- 5
# Ground truth for person and item parameters
set.seed(11111)  # for reproducibility
tau <- round(rnorm(N, 0, 0.25), 3)
tau <- tau - mean(tau)  # Enforce identifiability constraint
beta <- round(rnorm(J, 1.8, 0.25), 3)
alpha <- round(runif(J, 1.75, 3.25), 3)
# Data generation function
generate_data <- function(N, J, true_tau, true_beta, true_alpha, c){
time_matrix <- matrix(nrow = N, ncol = J)
for(j in 1:J){
for(i in 1:N){
time_matrix[i,j] <- rnorm(1, mean = true_beta[j] - true_tau[i], sd = 1/true_alpha[j])
}
}
censored_data <- pmin(time_matrix, c)
censor_rate <- sum(time_matrix > c) / (N*J)
return(list(time_matrix = time_matrix, censored_data = censored_data, censor_rate = censor_rate))
}
raw_data <- generate_data(N, J, tau, beta, alpha, 2.5)
# Log-likelihood function
log_likelihood_function <- function(params, dat, N, J, c){
tau <- params[1:N]
alpha <- params[(N+1):(N+J)]
beta <- params[(N+J+1):(N+2*J)]
ll <- 0
for(i in 1:N) {
for(j in 1:J) {
if(dat[i,j] < c) {
ll <- ll + dnorm(dat[i,j], mean = beta[j] - tau[i], sd = 1/alpha[j], log = TRUE)
} else {
ll <- ll + dnorm(dat[i,j], mean = beta[j] - tau[i], sd = 1/alpha[j])
+ pnorm(c, mean = beta[j] - tau[i], sd = 1/alpha[j], lower.tail = FALSE, log.p = TRUE)
}
}
}
return(-ll)
}
# Initial parameter values
init_params <- c(rep(0, N), rep(1, J), rep(0, J))
max_iter <- 100
for(iter in 1:max_iter){
}
# Optimization
optim_result <- optim(init_params, log_likelihood_function,
dat = raw_data$censored_data, N = N, J = J, c = 2.5,
method = "L-BFGS-B")
# Extract estimated parameters
estimated_tau <- optim_result$par[1:N]
estimated_alpha <- optim_result$par[(N+1):(N+J)]
estimated_beta <- optim_result$par[(N+J+1):(N+2*J)]
# Enforce identifiability constraint on estimated tau
estimated_tau <- estimated_tau - mean(estimated_tau)
# Compare true and estimated parameters
print(cor(tau, estimated_tau))
print(cor(alpha, estimated_alpha))
print(cor(beta, estimated_beta))
# Initial parameter values
init_params <- c(rep(0, N), rep(1, J), rep(0, J))
max_iter <- 100
# JMLE optimization
for(iter in 1:max_iter){
optim_result <- optim(init_params, log_likelihood_function,
dat = raw_data$censored_data, N = N, J = J, c = 2.5,
method = "L-BFGS-B")
new_params <- optim_result$par
# Extract estimated parameters
estimated_tau <- optim_result$par[1:N]
estimated_alpha <- optim_result$par[(N+1):(N+J)]
estimated_beta <- optim_result$par[(N+J+1):(N+2*J)]
## stopping rule
if(max(abs(new_params - old_params)) < 1e-6){
break
}
}
# Enforce identifiability constraint on estimated tau
estimated_tau <- estimated_tau - mean(estimated_tau)
# Compare true and estimated parameters
print(cor(tau, estimated_tau))
print(cor(alpha, estimated_alpha))
print(cor(beta, estimated_beta))
plot(estimated_tau, tau)
plot(estimated_alpha, alpha)
estimated_tau
estimated_alpha
alpha
optim_result <- optim(init_params, log_likelihood_function,
dat = raw_data$censored_data, N = N, J = J, c = 2.5,
method = "L-BFGS-B")
new_params <- optim_result$par
# Extract estimated parameters
estimated_tau <- optim_result$par[1:N]
estimated_alpha <- optim_result$par[(N+1):(N+J)]
estimated_beta <- optim_result$par[(N+J+1):(N+2*J)]
estimated_alpha
alpha
optim_result <- optim(init_params, log_likelihood_function,
dat = raw_data$censored_data, N = N, J = J, c = 2.5,
method = "SANN")
new_params <- optim_result$par
# Extract estimated parameters
estimated_tau <- optim_result$par[1:N]
estimated_alpha <- optim_result$par[(N+1):(N+J)]
estimated_beta <- optim_result$par[(N+J+1):(N+2*J)]
estimated_alpha
estimated_tau
tau
cor(estimated_tau, tau)
cor(estimated_alpha, alpha)
cor(estimated_beta, beta)
# Initial parameter values
init_params <- c(rep(0, N), rep(1, J), rep(0, J))
max_iter <- 50
# JMLE optimization
for(iter in 1:max_iter){
optim_result <- optim(init_params, log_likelihood_function,
dat = raw_data$censored_data, N = N, J = J, c = 2.5,
method = "L-BFGS-B")
new_params <- optim_result$par
# Extract estimated parameters
estimated_tau <- optim_result$par[1:N]
estimated_alpha <- optim_result$par[(N+1):(N+J)]
estimated_beta <- optim_result$par[(N+J+1):(N+2*J)]
## stopping rule
if(max(abs(new_params - old_params)) < 1e-5){
break
}
}
plot(estimated_tau, tau)
plot(estimated_alpha, alpha)
# Enforce identifiability constraint on estimated tau
estimated_tau <- estimated_tau - mean(estimated_tau)
# Compare true and estimated parameters
print(cor(tau, estimated_tau))
print(cor(alpha, estimated_alpha))
print(cor(beta, estimated_beta))
library(numDeriv)
# The number of test takers and number of items
N <- 50
J <- 5
# Ground truth for person and item parameters
set.seed(11111)  # for reproducibility
tau <- round(rnorm(N, 0, 0.25), 3)
tau <- tau - mean(tau)  # Enforce identifiability constraint
beta <- round(rnorm(J, 1.8, 0.25), 3)
alpha <- round(runif(J, 1.75, 3.25), 3)
# Data generation function
generate_data <- function(N, J, true_tau, true_beta, true_alpha, c){
time_matrix <- matrix(nrow = N, ncol = J)
for(j in 1:J){
for(i in 1:N){
time_matrix[i,j] <- rnorm(1, mean = true_beta[j] - true_tau[i], sd = 1/true_alpha[j])
}
}
censored_data <- pmin(time_matrix, c)
censor_rate <- sum(time_matrix > c) / (N*J)
return(list(time_matrix = time_matrix, censored_data = censored_data, censor_rate = censor_rate))
}
raw_data <- generate_data(N, J, tau, beta, alpha, 2.5)
# Log-likelihood function
log_likelihood_function <- function(params, dat, N, J, c){
tau <- params[1:N]
alpha <- params[(N+1):(N+J)]
beta <- params[(N+J+1):(N+2*J)]
ll <- 0
for(i in 1:N) {
for(j in 1:J) {
if(dat[i,j] < c) {
ll <- ll + dnorm(dat[i,j], mean = beta[j] - tau[i], sd = 1/alpha[j], log = TRUE)
} else {
ll <- ll + dnorm(dat[i,j], mean = beta[j] - tau[i], sd = 1/alpha[j])
+ pnorm(c, mean = beta[j] - tau[i], sd = 1/alpha[j], lower.tail = FALSE, log.p = TRUE)
}
}
}
return(-ll)
}
# Initial parameter values
init_params <- c(rep(0, N), rep(1, J), rep(0, J))
max_iter <- 50
# JMLE optimization
for(iter in 1:max_iter){
optim_result <- optim(init_params, log_likelihood_function,
dat = raw_data$censored_data, N = N, J = J, c = 2.5,
method = "SANN")
new_params <- optim_result$par
# Extract estimated parameters
estimated_tau <- optim_result$par[1:N]
estimated_alpha <- optim_result$par[(N+1):(N+J)]
estimated_beta <- optim_result$par[(N+J+1):(N+2*J)]
## stopping rule
if(max(abs(new_params - old_params)) < 1e-5){
break
}
}
plot(estimated_tau, tau)
plot(estimated_alpha, alpha)
# Enforce identifiability constraint on estimated tau
estimated_tau <- estimated_tau - mean(estimated_tau)
# Compare true and estimated parameters
print(cor(tau, estimated_tau))
print(cor(alpha, estimated_alpha))
print(cor(beta, estimated_beta))
estimated_alpha
optim_result <- optim(init_params, log_likelihood_function,
dat = raw_data$censored_data, N = N, J = J, c = 2.5,
method = "SANN")
new_params <- optim_result$par
# Extract estimated parameters
estimated_tau <- optim_result$par[1:N]
estimated_alpha <- optim_result$par[(N+1):(N+J)]
estimated_beta <- optim_result$par[(N+J+1):(N+2*J)]
estimated_alpha
alpha
tau
estimated_tau
library(numDeriv)
# The number of test takers and number of items
N <- 50
J <- 10
# Ground truth for person and item parameters
set.seed(11111)  # for reproducibility
tau <- round(rnorm(N, 0, 0.25), 3)
tau <- tau - mean(tau)  # Enforce identifiability constraint
beta <- round(rnorm(J, 1.8, 0.25), 3)
alpha <- round(runif(J, 1.75, 3.25), 3)
# Data generation function
generate_data <- function(N, J, true_tau, true_beta, true_alpha, c){
time_matrix <- matrix(nrow = N, ncol = J)
for(j in 1:J){
for(i in 1:N){
time_matrix[i,j] <- rnorm(1, mean = true_beta[j] - true_tau[i], sd = 1/true_alpha[j])
}
}
censored_data <- pmin(time_matrix, c)
censor_rate <- sum(time_matrix > c) / (N*J)
return(list(time_matrix = time_matrix, censored_data = censored_data, censor_rate = censor_rate))
}
raw_data <- generate_data(N, J, tau, beta, alpha, 2.5)
# Log-likelihood function
log_likelihood_function <- function(params, dat, N, J, c){
tau <- params[1:N]
alpha <- params[(N+1):(N+J)]
beta <- params[(N+J+1):(N+2*J)]
ll <- 0
for(i in 1:N) {
for(j in 1:J) {
if(dat[i,j] < c) {
ll <- ll + dnorm(dat[i,j], mean = beta[j] - tau[i], sd = 1/alpha[j], log = TRUE)
} else {
ll <- ll + dnorm(dat[i,j], mean = beta[j] - tau[i], sd = 1/alpha[j])
+ pnorm(c, mean = beta[j] - tau[i], sd = 1/alpha[j], lower.tail = FALSE, log.p = TRUE)
}
}
}
return(-ll)
}
# Initial parameter values
init_params <- c(rep(0, N), rep(1, J), rep(0, J))
max_iter <- 50
# JMLE optimization
for(iter in 1:max_iter){
optim_result <- optim(init_params, log_likelihood_function,
dat = raw_data$censored_data, N = N, J = J, c = 2.5,
method = "SANN")
new_params <- optim_result$par
# Extract estimated parameters
estimated_tau <- optim_result$par[1:N]
estimated_alpha <- optim_result$par[(N+1):(N+J)]
estimated_beta <- optim_result$par[(N+J+1):(N+2*J)]
## stopping rule
if(max(abs(new_params - old_params)) < 1e-5){
break
}
}
plot(estimated_tau, tau)
plot(estimated_alpha, alpha)
# Enforce identifiability constraint on estimated tau
estimated_tau <- estimated_tau - mean(estimated_tau)
# Compare true and estimated parameters
print(cor(tau, estimated_tau))
print(cor(alpha, estimated_alpha))
print(cor(beta, estimated_beta))
estimated_alpha
tau
estimated_tau
data.frame(estimated_tau, tau)
optim_result <- optim(init_params, log_likelihood_function,
dat = raw_data$censored_data, N = N, J = J, c = 2.5,
method = "MLE")
optim_result <- optim(init_params, log_likelihood_function,
dat = raw_data$censored_data, N = N, J = J, c = 2.5,
method = "L-BFGS-B")
library(numDeriv)
# The number of test takers and number of items
N <- 50
J <- 10
# Ground truth for person and item parameters
set.seed(11111)  # for reproducibility
tau <- round(rnorm(N, 0, 0.25), 3)
tau <- tau - mean(tau)  # Enforce identifiability constraint
beta <- round(rnorm(J, 1.8, 0.25), 3)
alpha <- round(runif(J, 1.75, 3.25), 3)
# Data generation function
generate_data <- function(N, J, true_tau, true_beta, true_alpha, c){
time_matrix <- matrix(nrow = N, ncol = J)
for(j in 1:J){
for(i in 1:N){
time_matrix[i,j] <- rnorm(1, mean = true_beta[j] - true_tau[i], sd = 1/true_alpha[j])
}
}
censored_data <- pmin(time_matrix, c)
censor_rate <- sum(time_matrix > c) / (N*J)
return(list(time_matrix = time_matrix, censored_data = censored_data, censor_rate = censor_rate))
}
raw_data <- generate_data(N, J, tau, beta, alpha, 2.5)
# Log-likelihood function for alpha and beta
log_likelihood_alpha_beta <- function(params, dat, N, J, c, fixed_tau){
alpha <- params[1:J]
beta <- params[(J+1):(2*J)]
ll <- 0
for(i in 1:N) {
for(j in 1:J) {
if(dat[i,j] < c) {
ll <- ll + dnorm(dat[i,j], mean = beta[j] - fixed_tau[i], sd = 1/alpha[j], log = TRUE)
} else {
ll <- ll + log(dnorm(c, mean = beta[j] - fixed_tau[i], sd = 1/alpha[j]) +
pnorm(c, mean = beta[j] - fixed_tau[i], sd = 1/alpha[j], lower.tail = FALSE))
}
}
}
return(-ll)
}
# Log-likelihood function for tau
log_likelihood_tau <- function(params, dat, N, J, c, fixed_alpha, fixed_beta){
tau <- params
ll <- 0
for(i in 1:N) {
for(j in 1:J) {
if(dat[i,j] < c) {
ll <- ll + dnorm(dat[i,j], mean = fixed_beta[j] - tau[i], sd = 1/fixed_alpha[j], log = TRUE)
} else {
ll <- ll + log(dnorm(c, mean = fixed_beta[j] - tau[i], sd = 1/fixed_alpha[j]) +
pnorm(c, mean = fixed_beta[j] - tau[i], sd = 1/fixed_alpha[j], lower.tail = FALSE))
}
}
}
return(-ll)
}
# Initial parameter values
init_tau <- rep(0, N)
init_alpha <- rep(1, J)
init_beta <- rep(0, J)
max_iter <- 50
tolerance <- 1e-5
# Alternating optimization
for(iter in 1:max_iter){
# Optimize alpha and beta
optim_result_ab <- optim(c(init_alpha, init_beta), log_likelihood_alpha_beta,
dat = raw_data$censored_data, N = N, J = J, c = 2.5,
fixed_tau = init_tau,
method = "L-BFGS-B",
lower = c(rep(0.1, J), rep(-Inf, J)),
upper = c(rep(10, J), rep(Inf, J)))
new_alpha <- optim_result_ab$par[1:J]
new_beta <- optim_result_ab$par[(J+1):(2*J)]
# Optimize tau
optim_result_tau <- optim(init_tau, log_likelihood_tau,
dat = raw_data$censored_data, N = N, J = J, c = 2.5,
fixed_alpha = new_alpha, fixed_beta = new_beta,
method = "BFGS")
new_tau <- optim_result_tau$par
new_tau <- new_tau - mean(new_tau)  # Enforce identifiability constraint
# Check convergence
if(max(abs(c(new_alpha - init_alpha, new_beta - init_beta, new_tau - init_tau))) < tolerance){
break
}
# Update initial values for next iteration
init_alpha <- new_alpha
init_beta <- new_beta
init_tau <- new_tau
print(paste("Iteration", iter, "completed"))
}
# Final parameter estimates
estimated_alpha <- init_alpha
estimated_beta <- init_beta
estimated_tau <- init_tau
# Compare true and estimated parameters
print(cor(tau, estimated_tau))
print(cor(alpha, estimated_alpha))
print(cor(beta, estimated_beta))
abs(c(new_alpha - init_alpha, new_beta - init_beta, new_tau - init_tau)))
tau - mean(tau)
tau
estimated_tau
data.frame(estimated_tau, tau)
mean((estimated_tau - tau)^2)
plot(tau, estimated_tau)
