install.packages("tidyverse")
install.packages('LNIRT')
install.packages(c('mirt', 'metafor'))
henlo, how you doing<
what up
you are welcome
i would like to push teh keyboard further
thank you you are welcome
getwd()
### DIF lasso implementation for uniform DIF
setwd(dirname(rstudioapi::documentPath()))
library(glmnet)
source('dif regression functions.R')
set.seed(1111)
# conditions
N = 500
N_dif = 100
J = 20
# Item and person parameters
tau = round(rnorm(N, 0, 0.3), 3)
beta = round(rnorm(J, 4, 0.45), 3)
alpha = round(rnorm(J, 1.85, 0.15), 3)
delta_beta = c(0, 0.1, 0.2, 0.3, 0.4, 0.5)
G = c(rep(1,N_dif), rep(0,N - N_dif))
#### start here:
zero_rates_vec = c()
for(b in 1:length(delta_beta)){
delta_b = delta_beta[b]
count0 = c()
for(i in 1:100){
## generate data
initial_time = data_generation(N = N, J = J, N_dif = N_dif, tau, beta, alpha)
dif_matrix = dif_applier(initial_time, N_dif, 1,
tau, alpha, beta, delta_b)
tau_hat = tau_estimation(dif_matrix, N)
## lasso regression
cv_model = cv.glmnet(x = cbind(tau_hat, G), y = dif_matrix, alpha = 1,
family = 'mgaussian', type.measure = 'mse')
best_lambda = cv_model$lambda.min
test_model = glmnet(x =cbind(tau_hat, G) ,y = dif_matrix, alpha = 1,
lambda = best_lambda, family = 'mgaussian')
## store all the coefficients
beta1 = c()
beta2 = c()
for(j in 1:J){
beta1=c(beta1,test_model$beta[[j]][1])
beta2=c(beta2,test_model$beta[[j]][2])
}
## relative contribution
rel_contri=c()
for(j in 1:J){
rel_contri=c(rel_contri, abs(beta2[j])/sum(abs(beta2)))
}
if(identical(which(rel_contri >= 0.2), integer(0))){
print(i)
count0 = c(count0, i)
}
}
count0
zero_rates = length(count0) / 100
zero_rates_vec = c(zero_rates_vec, zero_rates)
}
zero_rates_vec
# Create a data frame for plotting
plot_data <- data.frame(
delta_beta = delta_beta,
zero_rates = zero_rates_vec
)
# Create the plot
plot(plot_data$delta_beta,
1 - plot_data$zero_rates,
type = "o",  # Points and lines
col = "red",
lwd = 2,     # Line width
pch = 16,    # Point type
xlab = "Delta Beta",
ylab = "Power Rates",
main = "Power Rates",
ylim = c(0, 1))
109/358
rstudioapi::addTheme("https://raw.githubusercontent.com/batpigandme/night-owlish/master/rstheme/night-owlish.rstheme", apply = TRUE)
3/5
123/358
###############################
### ptg main analysis script
###############################
library(tidyverse)
library(readxl)
library(metafor)
library(psych)
library(kableExtra)
library(modelsummary)
setwd(dirname(rstudioapi::documentPath()))
## load data
shortlist = read_excel('effect_sizes_and_moderators.xlsx')
## look at how many studies uses PTGI
shortlist %>% group_by(`scale type`) %>% count() # 20 PTGI and 10 PTGI-SF
## we can do normalization or we can perform separate analysis for these two types of studies
## check the sample size
sum(shortlist$`sample size`) ## overall
PTGI_dat = shortlist %>% filter(`scale type` == 'PTGI')
PTGISF_dat = shortlist %>% filter(`scale type` != 'PTGI')
################################################################
################################################################
#### stretch PTGI-SF
PTGISF_transformed = PTGISF_dat %>% mutate(`effect size` = `effect size` / 10 * 21) %>%
mutate(sd = sqrt(sd^2 * 2.1^2))
PTGISF_transformed
PTGI = rbind(PTGI_dat, PTGISF_transformed)
head(PTGI)
### start analysis with all the studies (PTGI gets successfully transformed)
PTGI_num = sum((PTGI_dat$`sample size` - 1) * PTGI_dat$sd^2)
PTGI_denom = sum(PTGI_dat$`sample size`) - length(PTGI_dat$`sample size`)
PTGI_sp = PTGI_num / PTGI_denom
PTGI_pooled_sd = sqrt(PTGI_sp)
PTGI_pooled_sd
cutoff = 45
PTGI_g = PTGI %>%
mutate(PTGI_num = (sum(`sample size`) - 1) * sd^2) %>%
mutate(PTGI_denom = sum(`sample size`) - length(`sample size`)) %>%
mutate(PTGI_pooled_sd = sqrt(PTGI_num / PTGI_denom)) %>%
mutate(g = (`effect size` - cutoff) / PTGI_pooled_sd) %>%
mutate(v_g = 2 * (1 - 0) / (`sample size`) + g^2 / (2 * (`sample size` - 1)))
## now we have the ingredient to perform meta analysis
PTGI_g[,c('g', 'v_g')]
## we run intercept only model for main analysis (this would be random intercept model)
main_analysis_model_PTGI = rma(g ~ 1, vi = v_g, data = PTGI_g)
main_analysis_model_PTGI
################################################################
## Subgroup analysis
################################################################
## PTSD
PTGI_PTSD = rma(g ~ PTSD, vi = v_g, data = PTGI_g)
PTGI_PTSD
sum(PTGI_g$`sample size` * PTGI_g$PTSD)
PTGI_g$Source[ifelse(PTGI_g$PTSD == 1, TRUE, FALSE)]
### Anxiety Scales
PTGI_Anxiety = rma(g ~ Anxiety, vi = v_g, data = PTGI_g)
PTGI_Anxiety
sum(PTGI_g$Anxiety)
sum(PTGI_g$`sample size` * PTGI_g$Anxiety)
PTGI_g$Source[ifelse(PTGI_g$Anxiety == 1, TRUE, FALSE)]
### Depression Scales
PTGI_Depression = rma(g ~ Depression, vi = v_g, data = PTGI_g)
PTGI_Depression
sum(PTGI_g$Depression)
sum(PTGI_g$`sample size` * PTGI_g$Depression)
PTGI_g$Source[ifelse(PTGI_g$Depression == 1, TRUE, FALSE)]
### social support scales
PTGI_Support = rma(g ~ `Social Support`, vi = v_g, data = PTGI_g)
PTGI_Support
sum(PTGI_g$`Social Support`)
sum(PTGI_g$`sample size` * PTGI_g$`Social Support`)
PTGI_g$Source[ifelse(PTGI_g$`Social Support` == 1, TRUE, FALSE)]
## coping scales
PTGI_Coping = rma(g ~ `Coping`, vi = v_g, data = PTGI_g)
PTGI_Coping
sum(PTGI_g$`Coping`)
sum(PTGI_g$`sample size` * PTGI_g$`Coping`)
PTGI_g$Source[ifelse(PTGI_g$`Coping` == 1, TRUE, FALSE)]
### religion scales
PTGI_religion = rma(g ~ `Sprituality/Religion`, vi = v_g, data = PTGI_g)
PTGI_religion
sum(PTGI_g$`Sprituality/Religion`)
sum(PTGI_g$`sample size` * PTGI_g$`Sprituality/Religion`)
PTGI_g$Source[ifelse(PTGI_g$`Sprituality/Religion` == 1, TRUE, FALSE)]
### coping and anxiety are significant with coping clearly significant.
################################################################
## Tables and Figures
################################################################
## forest plot
ptsd_sample = PTGI_g %>% filter(`PTSD` == 1) %>% dplyr::select(Source, `sample size`)
forest(main_analysis_model_PTGI,
header="Author(s) and Year", mlab="", shade=TRUE,
cex=0.75)
## create tables for main analysis (table 1 in the manuscript)
PTGI_main_analysis_table = PTGI_g %>% dplyr::select(Source, `sample size`,
`effect size`, sd, `Mean Age`, Countries, Groups) %>%
mutate(`effect size` = round(`effect size`,2)) %>%
mutate(`Mean Age` = round( as.numeric(`Mean Age`),2)) %>%
mutate(sd = round(sd,2))
## this is table 1
table_1 = PTGI_main_analysis_table %>%
kbl() %>%
kable_classic(full_width = F, html_font = "Cambria")
# table_1 %>% as_image(width = 4)
PTGI_main_analysis_table[1:40,] %>%
kbl() %>%
kable_classic(full_width = F, html_font = "Cambria")
PTGI_main_analysis_table[40:75,] %>%
kbl() %>%
kable_classic(full_width = F, html_font = "Cambria")
PTGI_main_analysis_table %>%
kbl() %>%
kable_classic(full_width = F, html_font = "Cambria")
## create tables for subgroup analysis (table 3 in the manuscript
PTGI_subgroup = PTGI %>% dplyr::select("Source","PTSD", "Anxiety",
"Depression", "Social Support",
"Coping","Sprituality/Religion") %>%
mutate(PTSD = ifelse(PTSD == 1, '✔', ' ')) %>%
mutate(Anxiety = ifelse(Anxiety == 1, '✔', ' ')) %>%
mutate(Depression = ifelse(Depression == 1, '✔', ' ')) %>%
mutate(`Social Support` = ifelse(`Social Support` == 1, '✔', ' ')) %>%
mutate(Coping = ifelse(Coping == 1, '✔', ' ')) %>%
mutate(`Sprituality/Religion` = ifelse(`Sprituality/Religion` == 1, '✔', ' '))
## this is table 3
PTGI_subgroup[1:40, ]  %>%
kbl() %>%
kable_classic(full_width = F, html_font = "Cambria")
PTGI_subgroup[41:75, ]  %>%
kbl() %>%
kable_classic(full_width = F, html_font = "Cambria")
## check age range
range(as.numeric(PTGI_g$`Mean Age`)[!is.na(as.numeric(PTGI_g$`Mean Age`))])
which(as.numeric(PTGI_g$`Mean Age`) == 16)
PTGI_g$Source
## table 2
line1 = c(" ", "Estimate", "se", 'Z', 'p', 'CI LB', 'CI UP', ' ')
line2 = c('Intercept', '1.95', '0.62', '3.16', '0.002', '0.74', '3.16', ' ')
line3= c(' Heterogeneity Statistics', ' ', ' ', ' ', ' ', ' ', ' ', ' ')
line4 = c(" ", "Tau", "Tau^2", 'I^2', 'H^2', 'df', 'Q', 'p')
line5 = c(" ", "5.34", "28.47", '99.99%', '9695', '74', '15829', '< 0.001')
table2 = rbind(c('Random Effects Model (k=75)', ' ', ' ', ' ', ' ', ' ', ' ', ' '),
c(" ", "Estimate", "se", 'Z', 'p', 'CI LB', 'CI UP', ' '),
c('Intercept', '1.95', '0.62', '3.16', '0.002', '0.74', '3.16', ' '),
c(' Heterogeneity Statistics', ' ', ' ', ' ', ' ', ' ', ' ', ' '),
c(" ", "Tau", "Tau^2", 'I^2', 'H^2', 'df', 'Q', 'p'),
c(" ", "5.34", "28.47", '99.99%', '9695', '74', '15829', '< 0.001'))
tibble(table2)
x = kbl(table2) %>% kable_classic(full_width = F, html_font = "Cambria")
row_spec(x,1, hline_after = TRUE)
## table 4
Correlate = c('Anxiety', 'Depression', 'PTSD', 'Social Support', 'Coping', 'Spirituality')
K = c(28, 19, 20, 17, 38, 25)
N = c(19522, 21802, 24033, 20912, 23386, 15263)
CI_lower = c(-4.83, 0.15, -0.42, -1.61, 0.02, -0.93)
CI_upper = c(0.13, -4.93, 1.49, 4.24, 4.82, 4.24)
I2 = c(99.99, 99.99, 99.99, 99.99, 99.99, 99.99)
kbl(data.frame(Correlate, K,N,CI_lower, CI_upper, I2)) %>% kable_classic(full_width = F, html_font = "Cambria")
### subgroup analysis
## exploring different population ()
shortlist = read_excel('effect_sizes_and_moderators.xlsx')
unique(shortlist$Groups)
significant_models = c()
for(i in unique(shortlist$Groups)){
temp_ptg = PTGI_g %>% filter(Groups == i)
temp_model = rma(g ~ 1, vi = v_g, data = temp_ptg)
if(temp_model$pval < 0.05){
print(temp_model)
significant_models = c(significant_models, i)
}
}
significant_models
sample_sizes = shortlist %>% group_by(Groups) %>%
summarise(total_sample_size = sum(`sample size`)) %>%
arrange(desc(total_sample_size))
sample_sizes[sample_sizes$Groups %in% significant_models, ]
## meta regression for the chosen groups (explore the first 3 categories with the most sample sizes)
# nurse
nurse_ptg = PTGI_g %>% filter(Groups == 'Nurses')
nurse_model = rma(g ~ 1, vi = v_g, data = nurse_ptg)
nurse_model
nurse_model$pval
# General
general_ptg = PTGI_g %>% filter(Groups == 'General')
general_model = rma(g ~ 1, vi = v_g, data = general_ptg)
general_model
# Patients
patient_ptg = PTGI_g %>% filter(Groups == 'Patients')
patient_model = rma(g ~ 1, vi = v_g, data = patient_ptg)
patient_model
shortlist %>% select(Groups == "Medical Doctors" | Groups == "Nurses")
rlang::last_trace()
shortlist$Groups
###############################
### ptg main analysis script
###############################
library(tidyverse)
library(readxl)
library(metafor)
library(psych)
library(kableExtra)
library(modelsummary)
setwd(dirname(rstudioapi::documentPath()))
## load data
shortlist = read_excel('effect_sizes_and_moderators.xlsx')
## look at how many studies uses PTGI
shortlist %>% group_by(`scale type`) %>% count() # 20 PTGI and 10 PTGI-SF
head(PTGI_dat)
colnames(PTGI_dat)
rnorm(57, mean = 45, sd = PTGI_dat$sd)
calculate_effect_size = escalc(measure = "SMD",
m1i = `effect size`, sd1i = `sd`,
m2i = rnorm(57, mean = 45, sd = PTGI_dat$sd), sd2i = `sd`,
data = PTGI_dat)
calculate_effect_size = escalc(measure = "SMD",
m1i = `effect size`,
sd1i = `sd`,
n1i = 57,
m2i = rnorm(57, mean = 45, sd = PTGI_dat$sd),
sd2i = `sd`,
n2i = 57,
data = PTGI_dat)
calculate_effect_size = escalc(measure = "SMD",
m1i = PTGI_dat$`effect size`,
sd1i = PTGI_dat$sd,
n1i = PTGI_dat$`sample size`,  # Use actual sample sizes
m2i = rnorm(nrow(PTGI_dat), mean = 45, sd = PTGI_dat$sd),
sd2i = PTGI_dat$sd,
n2i = PTGI_dat$`sample size`,  # Use actual sample sizes
data = PTGI_dat)
nrow(PTGI_dat)
calculate_effect_size = escalc(measure = "SMD",
m1i = PTGI_dat$`effect size`,
sd1i = PTGI_dat$sd,
n1i = PTGI_dat$`sample size`,
m2i = rnorm(57, mean = 45, sd = mean(PTGI_dat$sd)),
sd2i = PTGI_dat$sd,
n2i = PTGI_dat$`sample size`)
PTGI_dat$`sample size`
calculate_effect_size
## we run intercept only model for main analysis (this would be random intercept model)
main_analysis_model_PTGI = rma(yi ~ 1, vi = vi, data = calculate_effect_size)
main_analysis_model_PTGI
## we run intercept only model for main analysis (this would be random intercept model)
main_analysis_model_PTGI = rma(yi, vi, data = calculate_effect_size)
main_analysis_model_PTGI
abs(calculate_effect_size$yi)
abs(calculate_effect_size$yi) > 3
abs(calculate_effect_size$yi) <= 3
filter_es = calculate_effect_size[abs(calculate_effect_size$yi) <= 3]
filter_es = calculate_effect_size[abs(calculate_effect_size$yi) <= 3,]
filter_es
dim(filter_es)
## we run intercept only model for main analysis (this would be random intercept model)
main_analysis_model_PTGI = rma(yi, vi, data = filter_es)
main_analysis_model_PTGI
# get some larger values out
filter_es = calculate_effect_size[abs(calculate_effect_size$yi) <= 2,]
## we run intercept only model for main analysis (this would be random intercept model)
main_analysis_model_PTGI = rma(yi, vi, data = filter_es)
main_analysis_model_PTGI
# get some larger values out
filter_es = calculate_effect_size[abs(calculate_effect_size$yi) <= 1.5,]
## we run intercept only model for main analysis (this would be random intercept model)
main_analysis_model_PTGI = rma(yi, vi, data = filter_es)
main_analysis_model_PTGI
# get some larger values out
filter_es = calculate_effect_size[abs(calculate_effect_size$yi) <= 1,]
## we run intercept only model for main analysis (this would be random intercept model)
main_analysis_model_PTGI = rma(yi, vi, data = filter_es)
main_analysis_model_PTGI
# get some larger values out
filter_es = calculate_effect_size[abs(calculate_effect_size$yi) <= 2.5,]
## we run intercept only model for main analysis (this would be random intercept model)
main_analysis_model_PTGI = rma(yi, vi, data = filter_es)
main_analysis_model_PTGI
PTGI_dat
main_analysis_model_PTGI
# influence
influence(main_analysis_model_PTGI)
## we run intercept only model for main analysis (this would be random intercept model)
main_analysis_model_PTGI = rma(yi, vi, data = calculate_effect_size)
main_analysis_model_PTGI
# influence
influence(main_analysis_model_PTGI)
# PTGISF_dat = shortlist %>% filter(`scale type` != 'PTGI')
#
# ## use escalc function to get effect sizes
calculate_effect_size = escalc(measure = "SMD",
m1i = PTGI_dat$`effect size`,
sd1i = PTGI_dat$sd,
n1i = PTGI_dat$`sample size`,  # Use actual sample sizes
m2i = rnorm(nrow(PTGI_dat), mean = 45, sd = PTGI_dat$sd),
sd2i = PTGI_dat$sd,
n2i = PTGI_dat$`sample size`,  # Use actual sample sizes
data = PTGI_dat,
append = TRUE)
calculate_effect_size ## noticed some quite high values; this indicates that maybe screening for outlier is needed
## we run intercept only model for main analysis (this would be random intercept model)
main_analysis_model_PTGI = rma(yi, vi, data = calculate_effect_size)
main_analysis_model_PTGI
# influence
influence(main_analysis_model_PTGI)
calculate_effect_size
###############################
### ptg main analysis script
###############################
library(tidyverse)
library(readxl)
library(metafor)
library(psych)
library(kableExtra)
library(modelsummary)
setwd(dirname(rstudioapi::documentPath()))
## load data
shortlist = read_excel('effect_sizes_and_moderators.xlsx')
shortlist %>% group_by(`scale type`) %>% count() # 20 PTGI and 10 PTGI-SF
## we can do normalization or we can perform separate analysis for these two types of studies
## check the sample size
sum(shortlist$`sample size`) ## overall
PTGI_dat = shortlist %>% filter(`scale type` == 'PTGI')
# PTGISF_dat = shortlist %>% filter(`scale type` != 'PTGI')
#
# ## use escalc function to get effect sizes
calculate_effect_size = escalc(measure = "SMD",
m1i = PTGI_dat$`effect size`,
sd1i = PTGI_dat$sd,
n1i = PTGI_dat$`sample size`,  # Use actual sample sizes
m2i = rnorm(nrow(PTGI_dat), mean = 45, sd = PTGI_dat$sd),
sd2i = PTGI_dat$sd,
n2i = PTGI_dat$`sample size`,  # Use actual sample sizes
data = PTGI_dat,
append = TRUE)
calculate_effect_size ## noticed some quite high values; this indicates that maybe screening for outlier is needed
## we run intercept only model for main analysis (this would be random intercept model)
main_analysis_model_PTGI = rma(yi, vi, data = calculate_effect_size)
main_analysis_model_PTGI
# forest plot
# influence
influence(main_analysis_model_PTGI)
# forest plot
forest(main_analysis_model_PTGI, slab = `Source`, header = "Study")
colnames(main_analysis_model_PTGI)
colnames(PTGI_dat)
mod.anxiety = rma(yi, vi, mods = ~ factor("Anxiety"), data = PTGI_dat)
mod.anxiety = rma(yi, vi, mods = ~ factor("Anxiety"), data = calculate_effect_size)
mod.anxiety = rma(yi, vi, mods = ~ factor(Anxiety), data = calculate_effect_size)
mod.anxiety
mod.anxiety = rma(yi, vi, mods = ~ Anxiety, data = calculate_effect_size)
mod.anxiety
calculate_effect_size$Groups
unique(calculate_effect_size)
unique(calculate_effect_size$Groups)
mod.groups = rma(yi, vi, mods = ~ factor(Groups), data = calculate_effect_size)
mod.groups
PTGI_dat$Groups
unique(PTGI_dat$Groups)
## examine PTGI data
high_exposure_group = PTGI_dat$Groups == "Front Line worker" |
PTGI_dat$Groups == "Nurses" |
PTGI_dat$Groups == "Medical Doctors" |
PTGI_dat$Groups == "Health Care Workers" |
PTGI_dat$Groups == "Patients"
high_exposure_group
sum(high_exposure_group)
PTGI_dat[high_exposure_group, -c("Groups", "scale type", "female proportion(Marg)")]
PTGI_dat[high_exposure_group,  -which(names(PTGI_dat) %in% c("Groups", "scale type", "female proportion(Marg)"))]
PTGI_dat[high_exposure_group,  -which(names(PTGI_dat) %in% c("Groups","Mean Age" ,"scale type", "female proportion(Marg)"))]
data.frame(PTGI_dat[high_exposure_group,  -which(names(PTGI_dat) %in% c("Groups", "Mean Age" ,"scale type", "female proportion(Marg)"))])
second.half <- data.frame(PTGI_dat[-high_exposure_group,
-which(names(PTGI_dat) %in%
c("Groups", "Mean Age" ,
"scale type",
"female proportion(Marg)"))])
dim(second.half)
dim(first.half)
first.half <- data.frame(PTGI_dat[high_exposure_group,
-which(names(PTGI_dat) %in%
c("Groups", "Mean Age" ,
"scale type",
"female proportion(Marg)"))])
dim(first.half)
first.half$sample.size
sum(first.half$sample.size)
sum(second.half$sample.size)
rbind(first.half, second.half)
dim(rbind(first.half, second.half))
high_exposure_group
dim(first.half)
dim(second.half)
second.half <- data.frame(PTGI_dat[!high_exposure_group,
-which(names(PTGI_dat) %in%
c("Groups", "Mean Age" ,
"scale type",
"female proportion(Marg)"))])
dim(second.half)
32 + 25
dim(rbind(first.half, second.half))
high_exposure_group
ifelse(high_exposure_group == TRUE, 1, 0)
cbind(rbind(first.half, second.half),ifelse(high_exposure_group == TRUE, 1, 0))
cbind(rbind(first.half, second.half),exposure = ifelse(high_exposure_group == TRUE, 1, 0))
new_dat <- cbind(rbind(first.half, second.half),
exposure = ifelse(high_exposure_group == TRUE, 1, 0))
new_dat
head(new_dat)
first.half$`effect size`
first.half
calculate_effect_size_2 <-escalc(measure = "SMD",
m1i = first.half$effect.size,
sd1i = first.half$sd,
n1i = first.half$sample.size,
m2i = second.half$effect.size,
sd2i = second.half$sd,
n2i = second.half$sample.size)
PTGI_dat$Countries
unique(PTGI_dat$Countries)
